{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRDpHPG56Num"
      },
      "outputs": [],
      "source": [
        "!apt-get -y install mysql-server\n",
        "!service mysql start\n",
        "!pip install mysql-connector-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mysql -e \"ALTER USER 'root'@'localhost' IDENTIFIED WITH 'mysql_native_password' BY 'your_password';FLUSH PRIVILEGES;\""
      ],
      "metadata": {
        "id": "ujsETFSB6ekL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mysql.connector\n",
        "\n",
        "# Establish connection\n",
        "mydb = mysql.connector.connect(\n",
        "  host=\"localhost\",\n",
        "  user=\"root\",\n",
        "  password=\"your_password\" # Use the password set in the previous step\n",
        ")\n",
        "\n",
        "# Create a cursor object\n",
        "mycursor = mydb.cursor()\n",
        "\n",
        "# Create a database (if it doesn't exist)\n",
        "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS mydatabase\")\n",
        "\n",
        "# Select the database\n",
        "mycursor.execute(\"USE mydatabase\")\n",
        "\n",
        "# Create a table\n",
        "mycursor.execute(\"CREATE TABLE IF NOT EXISTS customers (id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255), address VARCHAR(255))\")\n",
        "\n",
        "print(\"Table 'customers' created successfully.\")"
      ],
      "metadata": {
        "id": "AiJRdSJj6mYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert a single record\n",
        "sql = \"INSERT INTO customers (name, address) VALUES (%s, %s)\"\n",
        "val = (\"John Doe\", \"Highway 21\")\n",
        "mycursor.execute(sql, val)\n",
        "mydb.commit() # Commit the changes\n",
        "\n",
        "print(mycursor.rowcount, \"record inserted.\")\n",
        "\n",
        "# Insert multiple records\n",
        "sql = \"INSERT INTO customers (name, address) VALUES (%s, %s)\"\n",
        "val = [\n",
        "  (\"Peter\", \"Lowstreet 4\"),\n",
        "  (\"Amy\", \"Apple St 652\"),\n",
        "  (\"Hannah\", \"Mountain 21\")\n",
        "]\n",
        "mycursor.executemany(sql, val)\n",
        "mydb.commit()\n",
        "\n",
        "print(mycursor.rowcount, \"records inserted.\")\n",
        "\n",
        "# Close the connection\n",
        "mycursor.close()\n",
        "mydb.close()"
      ],
      "metadata": {
        "id": "CS_PkTvM6qAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Skip to content\n",
        "You said:\n",
        "Problem\n",
        "You are provided with a raw JSON file containing property records is located in data/\n",
        "Each row relates to a property. Each row mixes many unrelated attributes (property details, HOA data, rehab estimates, valuations, etc.).\n",
        "There are multiple Columns related to this property.\n",
        "The database is not normalized and lacks relational structure.\n",
        "Use the supplied Field Config.xlsx (in data/) to understand business semantics.\n",
        "Task\n",
        "Normalize the data:\n",
        "\n",
        "Develop a Python ETL script to read, clean, transform, and load data into your normalized MySQL tables.\n",
        "Refer the field config document for the relation of business logic\n",
        "Use primary keys and foreign keys to properly capture relationships\n",
        "Deliverable:\n",
        "\n",
        "Write necessary python and sql scripts\n",
        "Place your scripts in sql/ and scripts/\n",
        "The scripts should take the initial json to your final, normalized schema when executed\n",
        "Clearly document how to run your script, dependencies, and how it integrates with your database.\n",
        "Tech Stack:\n",
        "\n",
        "Python (include a requirements.txt) Use MySQL and SQL for all database work\n",
        "You may use any CLI or GUI for development, but the final changes must be submitted as python/ SQL scripts\n",
        "Do not use ORM migrations‚Äîwrite all SQL by hand  give step by step how to do this task\n",
        "ChatGPT said:\n",
        "To complete the ETL pipeline for normalizing a raw JSON dataset into a MySQL database using the provided Field Config.xlsx, follow the detailed step-by-step process below.\n",
        "\n",
        "‚úÖ STEP-BY-STEP ETL PLAN\n",
        "üìÅ Project Structure\n",
        "project/\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ data/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ raw_properties.json\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ Field Config.xlsx\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ scripts/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ etl.py\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt\n",
        "‚îÇ\n",
        "‚îú‚îÄ‚îÄ sql/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ create_schema.sql\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ insert_data.sql\n",
        "‚îÇ\n",
        "‚îî‚îÄ‚îÄ README.md\n",
        "STEP 1Ô∏è‚É£: Understand the Field Config File (Field Config.xlsx)\n",
        "‚úÖ Goal:\n",
        "Understand which JSON fields belong to which entity/table.\n",
        "\n",
        "Get info like:\n",
        "\n",
        "Field name\n",
        "\n",
        "Business meaning\n",
        "\n",
        "Target table (Property, HOA, Valuation, etc.)\n",
        "\n",
        "Data type\n",
        "\n",
        "‚úÖ Action:\n",
        "Open Field Config.xlsx.\n",
        "\n",
        "Create a mapping of:\n",
        "\n",
        "{\n",
        "  \"raw_field_name\": {\n",
        "    \"table\": \"target_table_name\",\n",
        "    \"column\": \"normalized_column_name\",\n",
        "    \"data_type\": \"str/int/float/date/etc.\"\n",
        "  }\n",
        "}\n",
        "üìå You‚Äôll use this mapping later to separate JSON fields into their respective tables.\n",
        "\n",
        "STEP 2Ô∏è‚É£: Design the Normalized Schema\n",
        "‚úÖ Goal:\n",
        "Create normalized tables with correct primary keys (PK) and foreign keys (FK).\n",
        "\n",
        "‚úÖ Action:\n",
        "Based on Field Config.xlsx, decide your schema.\n",
        "\n",
        "Example design:\n",
        "\n",
        "-- Property table\n",
        "CREATE TABLE Property (\n",
        "    property_id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "    address VARCHAR(255),\n",
        "    city VARCHAR(100),\n",
        "    state VARCHAR(50),\n",
        "    zip_code VARCHAR(20)\n",
        ");\n",
        "\n",
        "-- HOA table\n",
        "CREATE TABLE HOA (\n",
        "    hoa_id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "    property_id INT,\n",
        "    hoa_fee DECIMAL(10,2),\n",
        "    hoa_company VARCHAR(255),\n",
        "    FOREIGN KEY (property_id) REFERENCES Property(property_id)\n",
        ");\n",
        "\n",
        "-- Valuation table\n",
        "CREATE TABLE Valuation (\n",
        "    valuation_id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "    property_id INT,\n",
        "    estimated_value DECIMAL(12,2),\n",
        "    valuation_date DATE,\n",
        "    FOREIGN KEY (property_id) REFERENCES Property(property_id)\n",
        ");\n",
        "\n",
        "-- Rehab table\n",
        "CREATE TABLE RehabEstimate (\n",
        "    rehab_id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "    property_id INT,\n",
        "    cost DECIMAL(10,2),\n",
        "    notes TEXT,\n",
        "    FOREIGN KEY (property_id) REFERENCES Property(property_id)\n",
        ");\n",
        "üìÅ Save this in: sql/create_schema.sql\n",
        "\n",
        "STEP 3Ô∏è‚É£: Build the ETL Script (scripts/etl.py)\n",
        "‚úÖ Goal:\n",
        "Extract ‚Üí Transform ‚Üí Load data into the normalized schema.\n",
        "\n",
        "‚úÖ Dependencies (scripts/requirements.txt)\n",
        "pandas\n",
        "openpyxl\n",
        "mysql-connector-python\n",
        "Run this to install:\n",
        "\n",
        "pip install -r scripts/requirements.txt\n",
        "‚úÖ ETL Process Outline (in scripts/etl.py)\n",
        "import pandas as pd\n",
        "import json\n",
        "import mysql.connector\n",
        "\n",
        "# === Load Field Mapping ===\n",
        "config_df = pd.read_excel(\"data/Field Config.xlsx\")\n",
        "field_map = {}  # dict for mapping raw_field -> {table, column, datatype}\n",
        "\n",
        "for _, row in config_df.iterrows():\n",
        "    field_map[row['RawField']] = {\n",
        "        \"table\": row['TargetTable'],\n",
        "        \"column\": row['TargetField'],\n",
        "        \"type\": row['DataType']\n",
        "    }\n",
        "\n",
        "# === Load Raw JSON Data ===\n",
        "with open(\"data/raw_properties.json\") as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "# === Initialize storage for each table ===\n",
        "tables = {\n",
        "    \"Property\": [],\n",
        "    \"HOA\": [],\n",
        "    \"Valuation\": [],\n",
        "    \"RehabEstimate\": []\n",
        "}\n",
        "\n",
        "# === Extract & Transform ===\n",
        "for record in raw_data:\n",
        "    record_by_table = {\n",
        "        \"Property\": {},\n",
        "        \"HOA\": {},\n",
        "        \"Valuation\": {},\n",
        "        \"RehabEstimate\": {}\n",
        "    }\n",
        "\n",
        "    for raw_field, value in record.items():\n",
        "        if raw_field not in field_map:\n",
        "            continue\n",
        "        table = field_map[raw_field]['table']\n",
        "        column = field_map[raw_field]['column']\n",
        "        dtype = field_map[raw_field]['type']\n",
        "\n",
        "        # Type conversion\n",
        "        if dtype == \"int\":\n",
        "            value = int(value) if value else None\n",
        "        elif dtype == \"float\":\n",
        "            value = float(value) if value else None\n",
        "        elif dtype == \"date\":\n",
        "            value = pd.to_datetime(value, errors='coerce')\n",
        "        else:\n",
        "            value = str(value) if value else None\n",
        "\n",
        "        record_by_table[table][column] = value\n",
        "\n",
        "    # Add to final lists\n",
        "    property_row = record_by_table[\"Property\"]\n",
        "    tables[\"Property\"].append(property_row)\n",
        "\n",
        "    # Capture generated PK later for use in FK\n",
        "    current_index = len(tables[\"Property\"])\n",
        "\n",
        "    for related_table in [\"HOA\", \"Valuation\", \"RehabEstimate\"]:\n",
        "        record_by_table[related_table][\"property_id\"] = current_index  # temp PK assignment\n",
        "        tables[related_table].append(record_by_table[related_table])\n",
        "\n",
        "# === Load to MySQL ===\n",
        "\n",
        "# Setup DB connection\n",
        "conn = mysql.connector.connect(\n",
        "    host=\"localhost\",\n",
        "    user=\"youruser\",\n",
        "    password=\"yourpass\",\n",
        "    database=\"yourdb\"\n",
        ")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Insert Property first\n",
        "for row in tables[\"Property\"]:\n",
        "    columns = \", \".join(row.keys())\n",
        "    placeholders = \", \".join([\"%s\"] * len(row))\n",
        "    sql = f\"INSERT INTO Property ({columns}) VALUES ({placeholders})\"\n",
        "    cursor.execute(sql, list(row.values()))\n",
        "    conn.commit()\n",
        "\n",
        "# Get generated property_ids\n",
        "cursor.execute(\"SELECT property_id FROM Property\")\n",
        "property_ids = [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "# Insert related tables\n",
        "for table_name in [\"HOA\", \"Valuation\", \"RehabEstimate\"]:\n",
        "    for i, row in enumerate(tables[table_name]):\n",
        "        row[\"property_id\"] = property_ids[i]  # Assign real FK\n",
        "        columns = \", \".join(row.keys())\n",
        "        placeholders = \", \".join([\"%s\"] * len(row))\n",
        "        sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
        "        cursor.execute(sql, list(row.values()))\n",
        "        conn.commit()\n",
        "\n",
        "cursor.close()\n",
        "conn.close()\n",
        "üìÅ Save this in: scripts/etl.py\n",
        "\n",
        "STEP 4Ô∏è‚É£: Create Database & Tables\n",
        "‚úÖ Action:\n",
        "Open MySQL shell or use a GUI like MySQL Workbench.\n",
        "\n",
        "Run sql/create_schema.sql to create your tables.\n",
        "\n",
        "mysql -u youruser -p yourdb < sql/create_schema.sql\n",
        "STEP 5Ô∏è‚É£: Run the ETL Script\n",
        "‚úÖ Action:\n",
        "cd scripts/\n",
        "python etl.py\n",
        "‚úÖ This will:\n",
        "\n",
        "Read the JSON\n",
        "\n",
        "Transform it into normalized structure\n",
        "\n",
        "Insert it into your MySQL database\n",
        "\n",
        "‚úÖ FINAL DELIVERABLES\n",
        "scripts/etl.py\n",
        "Full ETL logic\n",
        "\n",
        "scripts/requirements.txt\n",
        "Python package dependencies\n",
        "\n",
        "sql/create_schema.sql\n",
        "All SQL table creation statements\n",
        "\n",
        "README.md\n",
        "# Property Data ETL Pipeline\n",
        "\n",
        "## How to Run\n",
        "\n",
        "### 1. Install Dependencies\n",
        "```bash\n",
        "pip install -r scripts/requirements.txt\n",
        "2. Setup Database\n",
        "Create your MySQL DB\n",
        "\n",
        "Run schema script:\n",
        "\n",
        "mysql -u youruser -p yourdb < sql/create_schema.sql\n",
        "3. Run ETL Script\n",
        "cd scripts/\n",
        "python etl.py\n",
        "Data Sources\n",
        "JSON File: data/raw_properties.json\n",
        "\n",
        "Field Mapping: data/Field Config.xlsx\n",
        "\n",
        "Output\n",
        "Data will be loaded into normalized tables:\n",
        "\n",
        "Property\n",
        "\n",
        "HOA\n",
        "\n",
        "Valuation\n",
        "\n",
        "RehabEstimate\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Would you like me to:\n",
        "- Generate the schema SQL for your dataset?\n",
        "- Help parse a sample of your Field Config or JSON?\n",
        "\n",
        "Just upload the files and I‚Äôll tailor the code to them.\n",
        "\n",
        "By messaging ChatGPT, you agree to our Terms and have read our Privacy Policy. See Cookie Preferences.\n",
        "Don't share sensitive info. Chats may be reviewed and used to train our models. Learn more\n",
        "\n",
        "\n",
        "\n",
        "Attach\n",
        "\n",
        "Search\n",
        "\n",
        "Study\n",
        "\n",
        "Voice\n",
        "No file chosenNo file chosen\n",
        "ChatGPT can make mistakes. Check important info. See Cookie Preferences.\n"
      ],
      "metadata": {
        "id": "TOvCkBIZ7qbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qNw8YcAA6egl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CM4JgwqD6edU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8O0M0LKL6eaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zF-0R8pS6eWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KY-iU7vo6eTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}